{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4458097,"sourceType":"datasetVersion","datasetId":2609801}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-27T08:52:59.175229Z","iopub.execute_input":"2025-01-27T08:52:59.175746Z","iopub.status.idle":"2025-01-27T08:52:59.665141Z","shell.execute_reply.started":"2025-01-27T08:52:59.175709Z","shell.execute_reply":"2025-01-27T08:52:59.663634Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# About Dataset","metadata":{}},{"cell_type":"markdown","source":"- UID, Product ID: Unique Identity; Won't be needed in Modeling\n- Type:  Product Quality -> L(Low), M(Medium), H(High)\n- tool wear failure (TWF), heat dissipation failure (HDF), power failure (PWF), overstrain failure (OSF), random failures (RNF)\n- Machine failure: Will be the output variable for the pre maintnance model.\n- Kudos to Dataset owner,for sharing it. It is one of the few dataset with detailed explantion to dataset and proper references.","metadata":{}},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import joblib\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.utils import resample\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_auc_score\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T09:03:37.55541Z","iopub.execute_input":"2025-01-27T09:03:37.555845Z","iopub.status.idle":"2025-01-27T09:03:37.562332Z","shell.execute_reply.started":"2025-01-27T09:03:37.555813Z","shell.execute_reply":"2025-01-27T09:03:37.561027Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Analysis","metadata":{}},{"cell_type":"code","source":"dataset = pd.read_csv('/kaggle/input/predictive-maintenance-dataset-ai4i-2020/ai4i2020.csv')\ndataset.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T08:53:12.214454Z","iopub.execute_input":"2025-01-27T08:53:12.215055Z","iopub.status.idle":"2025-01-27T08:53:12.292969Z","shell.execute_reply.started":"2025-01-27T08:53:12.215025Z","shell.execute_reply":"2025-01-27T08:53:12.291739Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset.columns","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-27T08:52:31.301Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset.describe()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-27T08:52:31.301Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset.isnull().sum()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-27T08:52:31.301Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(dataset['Machine failure'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T08:53:17.086346Z","iopub.execute_input":"2025-01-27T08:53:17.086745Z","iopub.status.idle":"2025-01-27T08:53:17.105886Z","shell.execute_reply.started":"2025-01-27T08:53:17.086718Z","shell.execute_reply":"2025-01-27T08:53:17.104446Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The above calculation state that the result is highly biased towards 'Machine failure' = 0, hence we need to sample the data. As of now I am thinking of oversamplung in order not to loose any information. If that won't work we can gave a look at other sampling methods.","metadata":{}},{"cell_type":"code","source":"# Check for duplicate rows\nduplicates = dataset.duplicated()\n\n# Count the number of duplicate rows\nnum_duplicates = duplicates.sum()\n\nprint(f\"Number of duplicate rows: {num_duplicates}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-27T08:52:31.302Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualising Continuous variables\ncontinuous_vars = ['Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]']\n\n# Plot distributions\nplt.figure(figsize=(15, 10))\nfor i, col in enumerate(continuous_vars, 1):\n    plt.subplot(3, 2, i)\n    sns.histplot(data=dataset, x=col, hue='Machine failure', kde=True, bins=30, palette='Set2')\n    plt.title(f'Distribution of {col} by Machine Failure')\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-27T08:52:31.302Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Maintaing distribution similar as oiginal dataset\n# Separate majority and minority classes\ndf_majority = dataset[dataset['Machine failure'] == 0]\ndf_minority = dataset[dataset['Machine failure'] == 1]\n\n# Define the target size for undersampling\ntarget_size = len(df_minority)\n\n# Create bins for continuous variables\ncontinuous_vars = ['Air temperature [K]', 'Process temperature [K]', \n                   'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]']\n\n# Add bin columns for each continuous variable in the majority class\nfor col in continuous_vars:\n    df_majority[f'{col}_bin'] = pd.qcut(df_majority[col], q=10, duplicates='drop')  # Quantile bins\n\n# Perform stratified sampling on the majority class\nundersampled_majority = pd.DataFrame()\n\n# For each bin in the continuous variables\nfor col in continuous_vars:\n    bin_column = f'{col}_bin'\n    for bin_value, group in df_majority.groupby(bin_column):\n        n_samples = int(len(group) / len(df_majority) * target_size)  # Proportional undersampling\n        undersampled_majority = pd.concat([undersampled_majority, resample(group, n_samples=n_samples, random_state=42, replace=False)])\n\n# Drop bin columns from the undersampled majority\nundersampled_majority = undersampled_majority.drop(columns=[f'{col}_bin' for col in continuous_vars])\n\n# Combine the undersampled majority and minority classes\nundersampled_dataset = pd.concat([undersampled_majority, df_minority]).sample(frac=1, random_state=42).reset_index(drop=True)\n\n# Verify class balance\nprint(undersampled_dataset['Machine failure'].value_counts())\n\n# Check the distribution (Optional)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(15, 10))\nfor i, col in enumerate(continuous_vars, 1):\n    plt.subplot(3, 2, i)\n    sns.kdeplot(data=dataset, x=col, hue='Machine failure', fill=True, alpha=0.5, label='Original', palette='Set2')\n    sns.kdeplot(data=undersampled_dataset, x=col, hue='Machine failure', fill=True, alpha=0.3, linestyle='--', label='Undersampled', palette='Set1')\n    plt.title(f'KDE of {col}: Original vs. Undersampled')\n    plt.legend()\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T08:53:25.190843Z","iopub.execute_input":"2025-01-27T08:53:25.191414Z","iopub.status.idle":"2025-01-27T08:53:27.576092Z","shell.execute_reply.started":"2025-01-27T08:53:25.191367Z","shell.execute_reply":"2025-01-27T08:53:27.574402Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Mapping 'Type', product quality; L:1, M:2, H:0\nlabel_encoder = LabelEncoder()\ndataset['Labled Type'] = label_encoder.fit_transform(dataset['Type'])\ndataset.head()\n\n#Lable Encoding for undersampled dataset as well\nundersampled_dataset['Labled Type'] = label_encoder.fit_transform(undersampled_dataset['Type'])\n# Though this step can be skipped as form the previous experiments this Feature is not that important for final model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T08:53:39.104682Z","iopub.execute_input":"2025-01-27T08:53:39.105062Z","iopub.status.idle":"2025-01-27T08:53:39.115482Z","shell.execute_reply.started":"2025-01-27T08:53:39.105037Z","shell.execute_reply":"2025-01-27T08:53:39.114076Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Investigating Failure\nfailure_columns = ['TWF', 'HDF', 'PWF', 'OSF', 'RNF']\ndataset['Failure'] = dataset[failure_columns].sum(axis=1)\nundersampled_dataset['Failure'] = undersampled_dataset[failure_columns].sum(axis=1)\ncol = ['Failure']\nsns.histplot(data=dataset, x='Failure')\nplt.title('Distribution of Failure')\nplt.xlabel('Failure')\nplt.ylabel('Frequency')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T08:53:44.604796Z","iopub.execute_input":"2025-01-27T08:53:44.605196Z","iopub.status.idle":"2025-01-27T08:53:44.841027Z","shell.execute_reply.started":"2025-01-27T08:53:44.60517Z","shell.execute_reply":"2025-01-27T08:53:44.839765Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"features= ['Labled Type', 'Air temperature [K]',\n       'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]',\n       'Tool wear [min]', 'Machine failure', 'TWF', 'HDF', 'PWF', 'OSF',\n       'RNF', 'Failure']\n\ncorrelation_matrix = dataset[features].corr()\nplt.figure(figsize=(8, 6))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\nplt.title('Correlation Matrix')","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-27T08:52:31.303Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"features= ['Labled Type', 'Air temperature [K]',\n       'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]',\n       'Tool wear [min]', 'Machine failure', 'TWF', 'HDF', 'PWF', 'OSF',\n       'RNF', 'Failure']\n\ncorrelation_matrix = undersampled_dataset[features].corr()\nplt.figure(figsize=(8, 6))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\nplt.title('Correlation Matrix')","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-27T08:52:31.303Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Relation of each type of Failure with other variale:\n- tool wear failure (TWF): Tool Wear\n- heat dissipation failure (HDF): Torque, Rotational Speed, Air Temperature\n- power failure (PWF): Rotational speed, Torque, OSF\n- overstrain failure (OSF): Tool Wear. Torque, Rotational Speed\nAnd these Failure further affects the machine Failure.\\\nFrom above statement it is cleare that above features results in minor failure that further results machine failure.\\\nWhere RNF have minor influence on Machine Failure, TWF hase some inluence on Machine Failure, whereas HDF, PWF, OSF have highly influence on Machine Fialure.","metadata":{}},{"cell_type":"markdown","source":"# Assess Feature Importance","metadata":{}},{"cell_type":"markdown","source":"Since I have bot catgorical and numerical dataset, hence I am coosing Rnadom Forest Classifirer for Assessing Feature Importance and It has one more benefit that is tis not sensitive to scaling. One might be thinking why not SVM or PCA. But we use SVM the realationship between the target and feature is quite complex. PCA helpful in high dimentionality data. Hence I decided to stick to Rnadom Forest.","metadata":{}},{"cell_type":"code","source":"X = dataset.drop(columns=['Machine failure', 'UDI', 'Product ID', 'Type'])\ny = dataset['Machine failure']\n\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# Handle imbalance using SMOTE\nsmote = SMOTE(random_state=42)\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n\n# Train Random Forest\nrf = RandomForestClassifier(random_state=42)\nrf.fit(X_train_resampled, y_train_resampled)\n\n# Get Feature Importance\nimportances = rf.feature_importances_\nfeature_names = X.columns\nfeature_importance_df = pd.DataFrame({'Features': feature_names, 'Importance': importances})\nfeature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\nprint(feature_importance_df)\n\n# Evaluate the model\ny_pred = rf.predict(X_test)\nprint(\"Classification Report:\")\nprint(classification_report(y_test, y_pred))\n\n# Calculate AUC-ROC\ny_pred_prob = rf.predict_proba(X_test)[:, 1]\nroc_auc = roc_auc_score(y_test, y_pred_prob)\nprint(f\"AUC-ROC: {roc_auc:.4f}\")\n\n# Cros Validation Score to wheck if the model is overfitting or not\ncv_scores = cross_val_score(rf, X_train_resampled, y_train_resampled, cv=5, scoring='roc_auc')\nprint(f\"Cross-validated AUC-ROC: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-27T08:52:31.303Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The above Cross-validation state that the model is overfitted, Lets do Feature Selection first and then analyse the model again.","metadata":{}},{"cell_type":"markdown","source":"# Feature Selection","metadata":{}},{"cell_type":"markdown","source":"I have decied to drop ['TWF', 'HDF', 'PWF', 'OSF','RNF'] as they don't have much influence on the machine failure but collection of which will affect the model all together. I am also droping 'Lable Type' as evern it if provides information of the product quality but that has minor influence on the 'Machine Failure'","metadata":{}},{"cell_type":"code","source":"X = dataset.drop(columns=['Machine failure', 'UDI', 'Product ID', 'Type',\n                         'TWF', 'HDF', 'PWF', 'OSF','RNF', 'Labled Type', 'Failure'])\ny = dataset['Machine failure']\n\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# Handle imbalance using SMOTE\nsmote = SMOTE(random_state=42)\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n\nrf = RandomForestClassifier(random_state=42)\nrf.fit(X_train_resampled, y_train_resampled)\n\ny_predict = rf.predict(X_test)\nprint(\"Classification Report:\")\nprint(classification_report(y_test, y_pred))\n\n# Calculate AUC-ROC\ny_pred_prob = rf.predict_proba(X_test)[:, 1]\nroc_auc = roc_auc_score(y_test, y_pred_prob)\nprint(f\"AUC-ROC: {roc_auc:.4f}\")\n\n# Cros Validation Score to wheck if the model is overfitting or not\ncv_scores = cross_val_score(rf, X_train_resampled, y_train_resampled, cv=5, scoring='roc_auc')\nprint(f\"Cross-validated AUC-ROC: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-27T08:52:31.303Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Hyper Parameter Tuning","metadata":{}},{"cell_type":"code","source":"# from sklearn.ensemble import RandomForestClassifier\n# from sklearn.model_selection import GridSearchCV, StratifiedKFold\n# from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n# from sklearn.preprocessing import StandardScaler\n# import numpy as np\n\n\n# X = dataset.drop(columns=['Machine failure', 'UDI', 'Product ID', 'Type',\n#                          'TWF', 'HDF', 'PWF', 'OSF','RNF', 'Labled Type', 'Failure'])\n# y = dataset['Machine failure']\n\n# # Split data into training and testing sets\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# # Handle imbalance using SMOTE\n# smote = SMOTE(random_state=42)\n# X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n\n# # Define the Random Forest model with class weighting\n# rf_model = RandomForestClassifier(random_state=42, class_weight='balanced')\n\n# # Set up the parameter grid for hyperparameter tuning\n# param_grid = {\n#     'n_estimators': [50, 100, 200],\n#     'max_depth': [5, 10, 15, None],\n#     'min_samples_split': [2, 5, 10],\n#     'min_samples_leaf': [1, 2, 4],\n#     'max_features': ['sqrt', 'log2', None]\n# }\n\n# # Stratified cross-validation\n# cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# # Grid Search for hyperparameter tuning\n# grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=cv, scoring='roc_auc', verbose=2, n_jobs=-1)\n# grid_search.fit(X_train, y_train)\n\n# # Best parameters and model\n# best_model = grid_search.best_estimator_\n# print(\"Best parameters:\", grid_search.best_params_)\n\n# # Evaluate on test data\n# y_pred = best_model.predict(X_test)\n# y_prob = best_model.predict_proba(X_test)[:, 1]\n\n# # Classification Report\n# print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n\n# # AUC-ROC\n# auc_score = roc_auc_score(y_test, y_prob)\n# print(\"AUC-ROC Score:\", auc_score)\n\n# # Plot ROC Curve\n# import matplotlib.pyplot as plt\n# fpr, tpr, _ = roc_curve(y_test, y_prob)\n# plt.figure(figsize=(8, 6))\n# plt.plot(fpr, tpr, label=f\"AUC-ROC: {auc_score:.4f}\")\n# plt.plot([0, 1], [0, 1], 'k--', label=\"Random Guessing\")\n# plt.xlabel(\"False Positive Rate\")\n# plt.ylabel(\"True Positive Rate\")\n# plt.title(\"ROC Curve\")\n# plt.legend()\n# plt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-27T08:52:31.303Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Splitting data into features (X) and target (y)\nX = dataset.drop(columns=['Machine failure', 'UDI', 'Product ID', 'Type', \n                          'TWF', 'HDF', 'PWF', 'OSF', 'RNF', 'Labled Type', 'Failure'])\ny = dataset['Machine failure']\n\n# Splitting into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n\n# Applying SMOTE for oversampling the minority class\nsmote = SMOTE(random_state=42)\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n\n# Defining the best parameters for the RandomForestClassifier\nparam_grid = {'max_depth': 10, 'max_features': None, 'min_samples_leaf': 4, \n              'min_samples_split': 2, 'n_estimators': 200}\n\n# Training the RandomForest model\nrf_best_model = RandomForestClassifier(random_state=42, class_weight='balanced', **param_grid)\nrf_best_model.fit(X_train_resampled, y_train_resampled)\n\n# Predicting the test data\ny_pred = rf_best_model.predict(X_test)\n\n# Predicting probabilities for AUC-ROC\ny_prob = rf_best_model.predict_proba(X_test)[:, 1]\n\n# Classification Report\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n\n# AUC-ROC Score\nauc_score = roc_auc_score(y_test, y_prob)\nprint(\"AUC-ROC Score:\", auc_score)\n\n# Cross-validation for AUC-ROC\ncv_scores = cross_val_score(rf_best_model, X_train_resampled, y_train_resampled, cv=5, scoring='roc_auc')\nprint(f\"Cross-validated AUC-ROC: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-27T08:52:31.304Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"I am still mot satisfied with the above model.","metadata":{}},{"cell_type":"markdown","source":"# Check Features Multicollinearity\nA **variance inflation factor (VIF)** score is a regression diagnostic that measures the correlation between independent variables in a model. It's used to detect multicollinearity, which can affect the reliability of a model's coefficients.\\\n\n**What does a VIF score indicate?**\\ \n- VIF = 1: No correlation between the variables\n- VIF between 1 and 5: Moderate correlation between the variables\n- VIF greater than 5: High correlation between the variables\n- VIF greater than 10: Serious correlation between the variables","metadata":{}},{"cell_type":"code","source":"# Calculate VIF for each feature\nvif_data = pd.DataFrame()\nvif_data['Feature'] = X.columns\nvif_data['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n\nprint(vif_data)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-27T08:52:31.304Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Since Air temprature and Process temprature are highly correlated, I am dropung Process Teparture based ob Correlation Metrix.","metadata":{}},{"cell_type":"code","source":"# Splitting data into features (X) and target (y)\nX = dataset.drop(columns=['Machine failure', 'UDI', 'Product ID', 'Type', \n                          'TWF', 'HDF', 'PWF', 'OSF', 'RNF', 'Labled Type', 'Failure', 'Process temperature [K]'])\ny = dataset['Machine failure']\n\n# Splitting into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n\n# Applying SMOTE for oversampling the minority class\nsmote = SMOTE(random_state=42)\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n\n# Defining the best parameters for the RandomForestClassifier\nparam_grid = {'max_depth': 10, 'max_features': None, 'min_samples_leaf': 4, \n              'min_samples_split': 2, 'n_estimators': 200}\n\n# Training the RandomForest model\nrf_best_model = RandomForestClassifier(random_state=42, class_weight='balanced', **param_grid)\nrf_best_model.fit(X_train_resampled, y_train_resampled)\n\n# Predicting the test data\ny_pred = rf_best_model.predict(X_test)\n\n# Predicting probabilities for AUC-ROC\ny_prob = rf_best_model.predict_proba(X_test)[:, 1]\n\n# Classification Report\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n\n# AUC-ROC Score\nauc_score = roc_auc_score(y_test, y_prob)\nprint(\"AUC-ROC Score:\", auc_score)\n\n# Cross-validation for AUC-ROC\ncv_scores = cross_val_score(rf_best_model, X_train_resampled, y_train_resampled, cv=5, scoring='roc_auc')\nprint(f\"Cross-validated AUC-ROC: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-27T08:52:31.304Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The above models don't seems to be over fitting anymore. But let's try Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"# Feature Engineering\nIf the two variables (Air temperature [K] and Process temperature [K]) are correlated because they measure similar phenomena, consider creating a combined feature:","metadata":{}},{"cell_type":"code","source":"dataset['Temp_diff'] = dataset['Process temperature [K]'] - dataset['Air temperature [K]']\n# dataset = dataset.drop(columns=['Air temperature [K]', 'Process temperature [K]'])\n\n# Splitting data into features (X) and target (y)\nX = dataset.drop(columns=['Machine failure', 'UDI', 'Product ID', 'Type', \n                          'TWF', 'HDF', 'PWF', 'OSF', 'RNF', 'Labled Type', 'Failure',\n                         'Air temperature [K]', 'Process temperature [K]'])\ny = dataset['Machine failure']\n\n# Splitting into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n\n# Applying SMOTE for oversampling the minority class\nsmote = SMOTE(random_state=42)\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n\n# Defining the best parameters for the RandomForestClassifier\nparam_grid = {'max_depth': 10, 'max_features': None, 'min_samples_leaf': 4, \n              'min_samples_split': 2, 'n_estimators': 200}\n\n# Training the RandomForest model\nrf_best_model = RandomForestClassifier(random_state=42, class_weight='balanced', **param_grid)\nrf_best_model.fit(X_train_resampled, y_train_resampled)\n\n# Predicting the test data\ny_pred = rf_best_model.predict(X_test)\n\n# Predicting probabilities for AUC-ROC\ny_prob = rf_best_model.predict_proba(X_test)[:, 1]\n\n# Classification Report\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n\n# AUC-ROC Score\nauc_score = roc_auc_score(y_test, y_prob)\nprint(\"AUC-ROC Score:\", auc_score)\n\n# Cross-validation for AUC-ROC\ncv_scores = cross_val_score(rf_best_model, X_train_resampled, y_train_resampled, cv=5, scoring='roc_auc')\nprint(f\"Cross-validated AUC-ROC: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-27T08:52:31.304Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Trying Regularization","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.metrics import classification_report, roc_auc_score\nfrom sklearn.model_selection import cross_val_score\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split\n\n# Create the new column 'Temp_diff'\ndataset['Temp_diff'] = dataset['Process temperature [K]'] - dataset['Air temperature [K]']\n\n# Splitting data into features (X) and target (y)\nX = dataset.drop(columns=['Machine failure', 'UDI', 'Product ID', 'Type', \n                          'TWF', 'HDF', 'PWF', 'OSF', 'RNF', 'Labled Type', 'Failure',\n                          'Air temperature [K]', 'Process temperature [K]'])\n\n# Rename columns to remove invalid characters\nX.columns = X.columns.str.replace(r\"[\\[\\]<> ]\", \"_\", regex=True)  # Replace special characters with underscores\n\ny = dataset['Machine failure']\n\n# Splitting into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n\n# Applying SMOTE for oversampling the minority class\nsmote = SMOTE(random_state=42)\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n\n# XGBoost with regularization\nxgb_model = XGBClassifier(\n    max_depth=10,\n    n_estimators=200,\n    learning_rate=0.1,\n    reg_alpha=1,  # L1 Regularization (LASSO)\n    reg_lambda=1,  # L2 Regularization (Ridge)\n    scale_pos_weight=10,  # Balancing class weights\n    random_state=42\n)\n\nxgb_model.fit(X_train_resampled, y_train_resampled)\n\n# Predicting the test data\ny_pred = xgb_model.predict(X_test)\ny_prob = xgb_model.predict_proba(X_test)[:, 1]\n\n# Evaluation\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\nauc_score = roc_auc_score(y_test, y_prob)\nprint(\"AUC-ROC Score:\", auc_score)\n\n# Cross-validation for AUC-ROC\ncv_scores = cross_val_score(xgb_model, X_train_resampled, y_train_resampled, cv=5, scoring='roc_auc')\nprint(f\"Cross-validated AUC-ROC: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-27T08:52:31.304Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Based on Undersampled Dataset","metadata":{}},{"cell_type":"code","source":"# Features and target\nX = undersampled_dataset.drop(columns=['Machine failure', 'UDI', 'Product ID', 'Type',\n                                       'TWF', 'HDF', 'PWF', 'OSF', 'RNF', 'Labled Type', 'Failure'])\ny = undersampled_dataset['Machine failure']\n\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# Initialize Random Forest Classifier\nrf = RandomForestClassifier(random_state=42)\nrf.fit(X_train, y_train)\n\n# Predictions\ny_predict = rf.predict(X_test)\n\n# Classification Report\nprint(\"Classification Report:\")\nprint(classification_report(y_test, y_predict))\n\n# Calculate AUC-ROC\ny_pred_prob = rf.predict_proba(X_test)[:, 1]  # Get probabilities for the positive class\nroc_auc = roc_auc_score(y_test, y_pred_prob)\nprint(f\"AUC-ROC: {roc_auc:.4f}\")\n\n# Cross-Validation Score to Check for Overfitting\ncv_scores = cross_val_score(rf, X_train, y_train, cv=5, scoring='roc_auc')  # Use `X_train` and `y_train`\nprint(f\"Cross-validated AUC-ROC: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T09:03:10.267214Z","iopub.execute_input":"2025-01-27T09:03:10.267658Z","iopub.status.idle":"2025-01-27T09:03:12.001002Z","shell.execute_reply.started":"2025-01-27T09:03:10.267607Z","shell.execute_reply":"2025-01-27T09:03:11.999765Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The above model has the best result so far, redicting Majority and Minority Features Correctly Hence I a shoosing this model for Deployment.","metadata":{}},{"cell_type":"markdown","source":"# Model Deployment","metadata":{}},{"cell_type":"code","source":"# Save the model\njoblib.dump(rf, 'random_forest_model.pkl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T09:03:14.806569Z","iopub.execute_input":"2025-01-27T09:03:14.807113Z","iopub.status.idle":"2025-01-27T09:03:14.864293Z","shell.execute_reply.started":"2025-01-27T09:03:14.80708Z","shell.execute_reply":"2025-01-27T09:03:14.862887Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}